import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt

from category_encoders import BinaryEncoder

from sklearn.preprocessing import LabelEncoder

from sklearn.pipeline import make_pipeline

from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LinearRegression

from sklearn.model_selection import cross_validate

from sklearn.preprocessing import StandardScaler


train = pd.read_csv(r"train.csv", index_col=False)
test = pd.read_csv(r"test.csv", index_col=False)
print("DF Size:" ,train.shape)
print("DF Size:" ,test.shape)
train.head(5)


train.describe()


train.describe(include =['O'])


train.info()


train.isnull().sum()


def fill_nan_with_frequencies(column):
    # Вычисляем частоты для каждого уникального значения в колонке
    frequencies = column.value_counts(normalize=True)
    
    # Создаем список значений для заполнения пропусков на основе частот
    values = frequencies.index
    probabilities = frequencies.values
    
    # Заменяем NaN случайными значениями на основе распределения частот
    nan_indices = column.isna()  # Получаем маску NaN
    
    # Используем np.random.choice для генерации значений по частотам
    fill_values = np.random.choice(values, size=nan_indices.sum(), p=probabilities)
    
    # Возвращаем колонку с заполненными значениями
    column.loc[nan_indices] = fill_values
    return column




def featureEngine(x, is_test = 0):
    ## Заполним нулевые значения с помощью частот, что позволит не терять данные, но и не создаст перевес к среднему значению, как еслиб заполняли средним значением.
    columns = x.columns
    for i in columns:
        if x[i].isnull().any():
            x[i] = fill_nan_with_frequencies(x[i].copy())

    ## Добавим пару параметров за счет разьединения прошлых, это положительно скажется на точности.
    x[['PassengerNumber', 'PassengerId']] = x['PassengerId'].astype(str).str.split("_", n=1, expand=True)
    x[['deck','numofcabinandside']] = x['Cabin'].astype(str).str.split("/", n=1, expand=True)
    x[['numofcabin','side']] = x['numofcabinandside'].astype(str).str.split("/", n=1, expand=True)

    ## Поменяем формат данных
    x['Age'] = x['Age'].astype(int)
    x['RoomService'] = x['RoomService'].astype(int)
    x['FoodCourt'] = x['FoodCourt'].astype(int)
    x['ShoppingMall'] = x['ShoppingMall'].astype(int)
    x['Spa'] = x['Spa'].astype(int)
    x['VRDeck'] = x['VRDeck'].astype(int)
    x['PassengerNumber'] = x['PassengerNumber'].astype(int)
    x['numofcabin'] = x['numofcabin'].astype(int)

    # Удалим лишнее
    x.drop(['numofcabinandside'], axis=1, inplace=True)
    x.drop(['PassengerId'], axis=1, inplace=True)
    x.drop(['Cabin'], axis=1, inplace=True)

    # Форматируем тип значений на булевы(был object так как были nan)
    x['VIP'] = x['VIP'].apply(lambda value: True if value == True else False)
    x['CryoSleep'] = x['CryoSleep'].apply(lambda value: True if value == True else False)
    if is_test == 0:
        x['Transported'] = x['Transported'].apply(lambda value: True if value == True else False)
    return x


featureEngine(train)
featureEngine(test, is_test=True)
train.head(5)


test.head(5)


new_order_train = ['PassengerNumber',
             'Name',
             'HomePlanet',
             'Destination',
             'deck',
             'numofcabin',
             'side',
             'Age',
             'CryoSleep',
             'VIP',
             'RoomService',
             'FoodCourt',
             'ShoppingMall',
             'Spa',
             'VRDeck',
             'Transported']  

new_order_test = ['PassengerNumber',
             'Name',
             'HomePlanet',
             'Destination',
             'deck',
             'numofcabin',
             'side',
             'Age',
             'CryoSleep',
             'VIP',
             'RoomService',
             'FoodCourt',
             'ShoppingMall',
             'Spa',
             'VRDeck']  

train = train.reindex(columns=new_order_train)
test = test.reindex(columns=new_order_test)
train.head(5)



test.head(5)


train.info()


print(train['Destination'].unique())
train.describe(include=['O'])


output_file_train = "clear_train.csv"
output_file_test = "clear_test.csv"
train.to_csv(output_file_train, index=True)  
test.to_csv(output_file_test, index=True)  
print(f"DataFrame сохранен в {output_file_train}")
print(f"DataFrame сохранен в {output_file_test}")


# Декодирование
def BinaryDecoder(encoded_df, original_df, encoder):
    decoded_df = pd.DataFrame()
    for col in encoder.cols:
        # Получаем количество бинарных столбцов для каждой переменной
        bin_cols = [c for c in encoded_df.columns if c.startswith(col)]
        # Получаем индексы уникальных комбинаций закодированных данных
        unique_binary_values = encoded_df[bin_cols].drop_duplicates().reset_index(drop=True)
        # Сопоставляем их с исходными значениями
        mapping = dict(zip(unique_binary_values.apply(tuple, axis=1), original_df[col].unique()))
        # Применяем декодирование
        decoded_df[col] = encoded_df[bin_cols].apply(lambda row: mapping[tuple(row)], axis=1)
    return decoded_df


#le = LabelEncoder()
#for i in ['deck', 'Name','HomePlanet', 'Destination', 'side']:
#    train[i] = le.fit_transform(train[i])
#    train[i] = le.fit_transform(test[i])
#
#train.head(5)
#test.head(5)

# Сохраняем исходные данные
original_train = train.copy()
original_test = test.copy()
#т.к эти параметры содержат по 2-3 различных значения применим BinaryEncoder
encoder = BinaryEncoder(cols=['HomePlanet', 'Destination', 'side'])

train = encoder.fit_transform(train)
test = encoder.fit_transform(test)
#т.к эти параметры содержат много различных значения применим LabelEncoder
le = LabelEncoder()
for i in ['deck', 'Name']:
    train[i] = le.fit_transform(train[i])
    test[i] = le.fit_transform(test[i])

train.head(5)


test.head(5)


corr = train.corr()
plt.figure(1, figsize=(8, 6)) 
sns.heatmap(corr,center=0) 
plt.show()
#train.corr()



